__import__('pysqlite3')
import sys
sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')

import streamlit as st
import os
from gtts import gTTS
from io import BytesIO
from dotenv import load_dotenv

# --- Imports (Updated for Latest LangChain v0.3) ---
from langchain_groq import ChatGroq
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma

# üî• Update 1: PromptTemplate in langchain_core 
from langchain_core.prompts import PromptTemplate 

# üî• Update 2: RetrievalQA 
from langchain.chains import RetrievalQA

# Import data from dataset.py
from dataset import get_data 

# --- Page Configuration ---
st.set_page_config(page_title="Bangla AI Chatbot", page_icon="ü§ñ", layout="wide")

# --- 1. Setup API Key ---
load_dotenv()
api_key = os.getenv("GROQ_API_KEY")

# Fallback if .env is missing
if not api_key:
    # üëá Paste your real API Key here
    api_key = "gsk_TOMAR_REAL_API_KEY_BOSHAO"

# --- 2. Initialize System (Cached for performance) ---
@st.cache_resource
def initialize_chatbot():
    # Load data from dataset.py
    docs = get_data()
    
    # Initialize Embeddings
    embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
    vectorstore = Chroma.from_documents(docs, embeddings)
    
    # Initialize LLM (Llama 3.1 8b Instant - Fastest)
    llm = ChatGroq(
        groq_api_key=api_key, 
        model_name="llama-3.1-8b-instant", 
        temperature=0
    )
    return vectorstore, llm

# Attempt to initialize the system
try:
    vectorstore, llm = initialize_chatbot()
except Exception as e:
    st.error(f"‚ùå Setup Error: {e}")
    st.stop()

# --- 3. Sidebar: Demo Questions ---
with st.sidebar:
    st.title("üìå Demo Questions")
    st.info("Try asking these questions to test the bot:")
    
    st.markdown("""
    **1. Education (‡¶∂‡¶ø‡¶ï‡ßç‡¶∑‡¶æ):**
    * ‡¶è‡¶á‡¶ö‡¶è‡¶∏‡¶∏‡¶ø ‡¶™‡¶∞‡ßÄ‡¶ï‡ßç‡¶∑‡¶æ ‡¶ï‡¶¨‡ßá ‡¶π‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá?
    
    **2. Health (‡¶∏‡ßç‡¶¨‡¶æ‡¶∏‡ßç‡¶•‡ßç‡¶Ø):**
    * ‡¶°‡ßá‡¶ô‡ßç‡¶ó‡ßÅ ‡¶ú‡ßç‡¶¨‡¶∞‡ßá‡¶∞ ‡¶≤‡¶ï‡ßç‡¶∑‡¶£ ‡¶ï‡ßÄ?
    
    **3. Sports (‡¶ñ‡ßá‡¶≤‡¶æ‡¶ß‡ßÅ‡¶≤‡¶æ):**
    * ‡¶≤‡¶ø‡¶ì‡¶®‡ßá‡¶≤ ‡¶Æ‡ßá‡¶∏‡¶ø ‡¶ï‡ßã‡¶® ‡¶¶‡ßá‡¶∂‡ßá‡¶∞ ‡¶ñ‡ßá‡¶≤‡ßã‡¶Ø‡¶º‡¶æ‡¶°‡¶º?
    
    **4. Technology (‡¶™‡ßç‡¶∞‡¶Ø‡ßÅ‡¶ï‡ßç‡¶§‡¶ø):**
    * ‡¶∞‚Äç‡ßç‡¶Ø‡¶æ‡¶Æ (RAM) ‡¶è‡¶∞ ‡¶ï‡¶æ‡¶ú ‡¶ï‡ßÄ?
    
    **5. Travel (‡¶≠‡ßç‡¶∞‡¶Æ‡¶£):**
    * ‡¶∏‡¶æ‡¶ú‡ßá‡¶ï ‡¶≠‡ßç‡¶Ø‡¶æ‡¶≤‡¶ø ‡¶ï‡ßã‡¶•‡¶æ‡¶Ø‡¶º ‡¶Ö‡¶¨‡¶∏‡ßç‡¶•‡¶ø‡¶§?
    """)
    st.write("---")
    st.caption("¬© Bangla RAG Chatbot Project")

# --- 4. Helper Function: Topic Detection ---
def detect_topic(query, llm):
    """
    Detects the topic of the user's query and maps it to the 
    dataset's metadata keys (e.g., 'shiksha', 'projukti').
    """
    q_lower = query.lower()

    # Strategy 1: Manual Keyword Checking (High Accuracy)
    if any(x in q_lower for x in ['‡¶è‡¶á‡¶ö‡¶è‡¶∏‡¶∏‡¶ø', '‡¶¨‡¶ø‡¶∂‡ßç‡¶¨‡¶¨‡¶ø‡¶¶‡ßç‡¶Ø‡¶æ‡¶≤‡¶Ø‡¶º', '‡¶™‡¶°‡¶º‡¶æ', 'exam', 'hsc', 'cse']): return 'shiksha'
    if any(x in q_lower for x in ['‡¶ú‡ßç‡¶¨‡¶∞', '‡¶°‡ßá‡¶ô‡ßç‡¶ó‡ßÅ', '‡¶ö‡¶ø‡¶ï‡¶ø‡ßé‡¶∏‡¶æ', '‡¶î‡¶∑‡¶ß', 'health', '‡¶ó‡ßç‡¶Ø‡¶æ‡¶∏‡ßç‡¶ü‡ßç‡¶∞‡¶ø‡¶ï']): return 'shastho'
    if any(x in q_lower for x in ['‡¶ñ‡ßá‡¶≤‡¶æ', '‡¶ï‡ßç‡¶∞‡¶ø‡¶ï‡ßá‡¶ü', '‡¶´‡ßÅ‡¶ü‡¶¨‡¶≤', '‡¶Æ‡ßá‡¶∏‡¶ø', 'sports', '‡¶ï‡ßç‡¶Ø‡¶æ‡¶™‡ßç‡¶ü‡ßá‡¶®']): return 'kheladhula'
    if any(x in q_lower for x in ['‡¶è‡¶Ü‡¶á', 'ai', 'ram', 'python', 'computer', '‡¶∞‚Äç‡ßç‡¶Ø‡¶æ‡¶Æ']): return 'projukti'
    if any(x in q_lower for x in ['‡¶ï‡¶ï‡ßç‡¶∏‡¶¨‡¶æ‡¶ú‡¶æ‡¶∞', '‡¶∏‡¶æ‡¶ú‡ßá‡¶ï', '‡¶≠‡ßç‡¶∞‡¶Æ‡¶£', 'tour', 'visa']): return 'vromon'

    # Strategy 2: AI Fallback (If keywords miss)
    valid_topics = ['education', 'health', 'sports', 'technology', 'travel']
    prompt = f"Classify topic: {valid_topics}. Return ONLY the topic name. Question: {query}"
    
    try:
        response = llm.invoke(prompt)
        ai_topic = response.content.strip().lower()
        
        mapping = {
            "education": "shiksha", "health": "shastho", "sports": "kheladhula",
            "technology": "projukti", "travel": "vromon"
        }
        
        for key in mapping:
            if key in ai_topic: return mapping[key]
        return "unknown"
    except:
        return "unknown"

# --- 5. Helper Function: Text to Speech ---
def text_to_speech(text):
    """
    Generate Audio from Text using Google TTS
    """
    try:
        tts = gTTS(text=text, lang='bn')
        audio_fp = BytesIO()
        tts.write_to_fp(audio_fp)
        return audio_fp
    except:
        return None

# --- 6. Main UI Layout ---
st.title("ü§ñ Bangla AI Assistant (Voice Enabled üîä)")
st.markdown("Ask questions about: **Education, Health, Sports, Technology, Travel**")

# Initialize chat history
if "messages" not in st.session_state:
    st.session_state.messages = []

# Display chat history
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- 7. Chat Logic (RAG) ---
if query := st.chat_input("‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶® ‡¶≤‡¶ø‡¶ñ‡ßÅ‡¶®... (Type your question)"):
    # Display user message
    st.session_state.messages.append({"role": "user", "content": query})
    with st.chat_message("user"):
        st.markdown(query)

    # Process AI Response
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        
        # A. Detect Topic
        topic = detect_topic(query, llm)
        
        # Mapping for UI Display
        display_map = {
            "shiksha": "‡¶∂‡¶ø‡¶ï‡ßç‡¶∑‡¶æ (Education)", "shastho": "‡¶∏‡ßç‡¶¨‡¶æ‡¶∏‡ßç‡¶•‡ßç‡¶Ø (Health)", 
            "kheladhula": "‡¶ñ‡ßá‡¶≤‡¶æ‡¶ß‡ßÅ‡¶≤‡¶æ (Sports)", "projukti": "‡¶™‡ßç‡¶∞‡¶Ø‡ßÅ‡¶ï‡ßç‡¶§‡¶ø (Technology)", 
            "vromon": "‡¶≠‡ßç‡¶∞‡¶Æ‡¶£ (Travel)", "unknown": "‡¶Ö‡¶ú‡¶æ‡¶®‡¶æ (Unknown)"
        }
        display_text = display_map.get(topic, "Unknown")
        
        # Variable to store text for voice generation
        voice_text = "" 

        # B. Handle Unknown Topics
        if topic == "unknown":
            response_text = "‡¶¶‡ßÅ‡¶É‡¶ñ‡¶ø‡¶§, ‡¶Ü‡¶Æ‡¶ø ‡¶è‡¶á ‡¶¨‡¶ø‡¶∑‡¶Ø‡¶º‡ßá ‡¶ú‡¶æ‡¶®‡¶ø ‡¶®‡¶æ‡•§ ‡¶¶‡¶Ø‡¶º‡¶æ ‡¶ï‡¶∞‡ßá ‡¶¨‡¶æ‡¶Æ‡¶™‡¶æ‡¶∂‡ßá‡¶∞ ‡¶°‡ßá‡¶Æ‡ßã ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶®‡¶ó‡ßÅ‡¶≤‡ßã ‡¶ö‡ßá‡¶∑‡ßç‡¶ü‡¶æ ‡¶ï‡¶∞‡ßÅ‡¶®‡•§"
            voice_text = response_text
        
        else:
            try:
                # C. Strict Prompt (Prevents Hallucinations)
                template = """
                You are a helpful assistant. Answer the question based ONLY on the provided Context.
                
                Context: {context}
                Question: {question}
                
                Rules:
                1. If the answer is in the context, output it exactly.
                2. If the answer is NOT in the context, say "‡¶¶‡ßÅ‡¶É‡¶ñ‡¶ø‡¶§, ‡¶Ü‡¶Æ‡¶æ‡¶∞ ‡¶°‡¶æ‡¶ü‡¶æ‡¶¨‡ßá‡¶ú‡ßá ‡¶∏‡¶†‡¶ø‡¶ï ‡¶â‡¶§‡ßç‡¶§‡¶∞ ‡¶®‡ßá‡¶á‡•§".
                3. Do not make up any information.
                
                Answer in Bangla:
                """
                QA_CHAIN_PROMPT = PromptTemplate.from_template(template)

                # D. Retrieve Documents (Filtered by Topic)
                retriever = vectorstore.as_retriever(
                    search_kwargs={"filter": {"topic": topic}, "k": 1}
                )
                
                qa_chain = RetrievalQA.from_chain_type(
                    llm=llm,
                    chain_type="stuff",
                    retriever=retriever,
                    chain_type_kwargs={"prompt": QA_CHAIN_PROMPT}
                )
                
                # E. Generate Answer
                res = qa_chain.invoke(query)
                answer = res['result']

                clean_answer = answer.replace("‡¶â‡¶§‡ßç‡¶§‡¶∞:", "").replace("Answer:", "").strip()
                
                response_text = f"**‡¶¨‡¶ø‡¶∑‡¶Ø‡¶º:** {display_text}\n\n{clean_answer}"
                voice_text = clean_answer # Only speak the answer part
                
            except Exception as e:
                response_text = f"Error: {e}"
                voice_text = "‡¶¶‡ßÅ‡¶É‡¶ñ‡¶ø‡¶§, ‡¶è‡¶ï‡¶ü‡¶ø ‡¶ü‡ßá‡¶ï‡¶®‡¶ø‡¶ï‡ßç‡¶Ø‡¶æ‡¶≤ ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá‡•§"

        # Display assistant response
        message_placeholder.markdown(response_text)
        
        # --- üîä Play Audio (TTS Feature) ---
        audio_data = text_to_speech(voice_text)
        if audio_data:
            st.audio(audio_data, format="audio/mp3")
        # -----------------------------------

        st.session_state.messages.append({"role": "assistant", "content": response_text})